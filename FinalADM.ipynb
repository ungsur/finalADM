{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/rungsunan/anaconda/envs/py36/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import string\n",
    " \n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from stop_words import get_stop_words\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import os\n",
    "from gensim import corpora, models\n",
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "\n",
    "from sklearn import  svm,neighbors\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV,cross_val_score\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas \n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.utils import resample\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The yelp dataset has a business json file, and reviews json file. We will import them as lists of dictionaries with json.loads and then convert to pandas to sort the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "business_file =  '/Volumes/data/yelp2016/yelp_dataset_challenge_academic_dataset/yelp_academic_dataset_business.json'\n",
    "bus_list = []\n",
    "with open(business_file) as data_file:    \n",
    "    for line in data_file:\n",
    "        bus_list.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews_file = '/Volumes/data/yelp2016/yelp_dataset_challenge_academic_dataset/yelp_academic_dataset_review.json'\n",
    "reviews = []\n",
    "with open(reviews_file) as data_file:    \n",
    "    for line in data_file:\n",
    "        reviews.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attributes': {'Accepts Credit Cards': True,\n",
       "  'Alcohol': 'none',\n",
       "  'Ambience': {'casual': False,\n",
       "   'classy': False,\n",
       "   'divey': False,\n",
       "   'hipster': False,\n",
       "   'intimate': False,\n",
       "   'romantic': False,\n",
       "   'touristy': False,\n",
       "   'trendy': False,\n",
       "   'upscale': False},\n",
       "  'Attire': 'casual',\n",
       "  'Caters': False,\n",
       "  'Delivery': False,\n",
       "  'Drive-Thru': False,\n",
       "  'Good For': {'breakfast': False,\n",
       "   'brunch': False,\n",
       "   'dessert': False,\n",
       "   'dinner': False,\n",
       "   'latenight': False,\n",
       "   'lunch': False},\n",
       "  'Good For Groups': True,\n",
       "  'Good for Kids': True,\n",
       "  'Has TV': False,\n",
       "  'Noise Level': 'average',\n",
       "  'Outdoor Seating': False,\n",
       "  'Parking': {'garage': False,\n",
       "   'lot': False,\n",
       "   'street': False,\n",
       "   'valet': False,\n",
       "   'validated': False},\n",
       "  'Price Range': 1,\n",
       "  'Take-out': True,\n",
       "  'Takes Reservations': False,\n",
       "  'Waiter Service': False},\n",
       " 'business_id': '5UmKMjUEUNdYWqANhGckJw',\n",
       " 'categories': ['Fast Food', 'Restaurants'],\n",
       " 'city': 'Dravosburg',\n",
       " 'full_address': '4734 Lebanon Church Rd\\nDravosburg, PA 15034',\n",
       " 'hours': {'Friday': {'close': '21:00', 'open': '11:00'},\n",
       "  'Monday': {'close': '21:00', 'open': '11:00'},\n",
       "  'Thursday': {'close': '21:00', 'open': '11:00'},\n",
       "  'Tuesday': {'close': '21:00', 'open': '11:00'},\n",
       "  'Wednesday': {'close': '21:00', 'open': '11:00'}},\n",
       " 'latitude': 40.3543266,\n",
       " 'longitude': -79.9007057,\n",
       " 'name': 'Mr Hoagie',\n",
       " 'neighborhoods': [],\n",
       " 'open': True,\n",
       " 'review_count': 7,\n",
       " 'stars': 3.5,\n",
       " 'state': 'PA',\n",
       " 'type': 'business'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bus_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'business_id': '5UmKMjUEUNdYWqANhGckJw',\n",
       " 'date': '2012-08-01',\n",
       " 'review_id': 'Ya85v4eqdd6k9Od8HbQjyA',\n",
       " 'stars': 4,\n",
       " 'text': 'Mr Hoagie is an institution. Walking in, it does seem like a throwback to 30 years ago, old fashioned menu board, booths out of the 70s, and a large selection of food. Their speciality is the Italian Hoagie, and it is voted the best in the area year after year. I usually order the burger, while the patties are obviously cooked from frozen, all of the other ingredients are very fresh. Overall, its a good alternative to Subway, which is down the road.',\n",
       " 'type': 'review',\n",
       " 'user_id': 'PUFPaY9KxDAcGqfsorJp3Q',\n",
       " 'votes': {'cool': 0, 'funny': 0, 'useful': 0}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The categories key in the business dictionary contains a list including cuisine type. We will convert these to pandas dataframes and match 'Chinese' and 'Italian' businesses to the text from the reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "business_df = pd.DataFrame.from_dict(bus_list)\n",
    "business_df = business_df[['business_id','categories']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cuisine_df = business_df.apply(lambda x: pd.Series(x['categories']),axis=1).stack().reset_index(level=1, drop=True)\n",
    "cuisine_df.name = 'cuisine'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>cuisine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5UmKMjUEUNdYWqANhGckJw</td>\n",
       "      <td>Fast Food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5UmKMjUEUNdYWqANhGckJw</td>\n",
       "      <td>Restaurants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UsFtqoBl7naz8AVUBZMjQQ</td>\n",
       "      <td>Nightlife</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cE27W9VPgO88Qxe4ol6y_g</td>\n",
       "      <td>Active Life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cE27W9VPgO88Qxe4ol6y_g</td>\n",
       "      <td>Mini Golf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id      cuisine\n",
       "0  5UmKMjUEUNdYWqANhGckJw    Fast Food\n",
       "0  5UmKMjUEUNdYWqANhGckJw  Restaurants\n",
       "1  UsFtqoBl7naz8AVUBZMjQQ    Nightlife\n",
       "2  cE27W9VPgO88Qxe4ol6y_g  Active Life\n",
       "2  cE27W9VPgO88Qxe4ol6y_g    Mini Golf"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business_df = business_df.drop('categories',axis=1).join(cuisine_df)\n",
    "business_df.columns = ['business_id','cuisine']\n",
    "business_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of businesses in dataset: 85901\n",
      "Number of restaurants: 26729\n",
      "Number of Italian or Chinese Restaurants: 3653\n",
      "Number of Italian Restaurants: 1939\n",
      "Number of Chinese Restaurants: 1714\n"
     ]
    }
   ],
   "source": [
    "print('Number of businesses in dataset: ' + str(len(business_df['business_id'].unique())))\n",
    "print('Number of restaurants: ' + str(len((business_df[(business_df.cuisine == 'Restaurants')]))))\n",
    "print('Number of Italian or Chinese Restaurants: ' + \n",
    "      str(len((business_df[(business_df.cuisine == 'Italian') | (business_df.cuisine == 'Chinese')]))))\n",
    "print('Number of Italian Restaurants: ' + str(len((business_df[(business_df.cuisine == 'Italian')]))))\n",
    "print('Number of Chinese Restaurants: ' + str(len((business_df[(business_df.cuisine == 'Chinese')]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>review_stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5UmKMjUEUNdYWqANhGckJw</td>\n",
       "      <td>2012-08-01</td>\n",
       "      <td>Ya85v4eqdd6k9Od8HbQjyA</td>\n",
       "      <td>4</td>\n",
       "      <td>Mr Hoagie is an institution. Walking in, it do...</td>\n",
       "      <td>review</td>\n",
       "      <td>PUFPaY9KxDAcGqfsorJp3Q</td>\n",
       "      <td>{'funny': 0, 'useful': 0, 'cool': 0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5UmKMjUEUNdYWqANhGckJw</td>\n",
       "      <td>2014-02-13</td>\n",
       "      <td>KPvLNJ21_4wbYNctrOwWdQ</td>\n",
       "      <td>5</td>\n",
       "      <td>Excellent food. Superb customer service. I mis...</td>\n",
       "      <td>review</td>\n",
       "      <td>Iu6AxdBYGR4A0wspR9BYHA</td>\n",
       "      <td>{'funny': 0, 'useful': 0, 'cool': 0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5UmKMjUEUNdYWqANhGckJw</td>\n",
       "      <td>2015-10-31</td>\n",
       "      <td>fFSoGV46Yxuwbr3fHNuZig</td>\n",
       "      <td>5</td>\n",
       "      <td>Yes this place is a little out dated and not o...</td>\n",
       "      <td>review</td>\n",
       "      <td>auESFwWvW42h6alXgFxAXQ</td>\n",
       "      <td>{'funny': 1, 'useful': 1, 'cool': 0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5UmKMjUEUNdYWqANhGckJw</td>\n",
       "      <td>2015-12-26</td>\n",
       "      <td>pVMIt0a_QsKtuDfWVfSk2A</td>\n",
       "      <td>3</td>\n",
       "      <td>PROS: Italian hoagie was delicious.  Friendly ...</td>\n",
       "      <td>review</td>\n",
       "      <td>qiczib2fO_1VBG8IoCGvVg</td>\n",
       "      <td>{'funny': 0, 'useful': 0, 'cool': 0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5UmKMjUEUNdYWqANhGckJw</td>\n",
       "      <td>2016-04-08</td>\n",
       "      <td>AEyiQ_Y44isJmNbMTyoMKQ</td>\n",
       "      <td>2</td>\n",
       "      <td>First the only reason this place could possibl...</td>\n",
       "      <td>review</td>\n",
       "      <td>qEE5EvV-f-s7yHC0Z4ydJQ</td>\n",
       "      <td>{'funny': 0, 'useful': 1, 'cool': 0}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id        date               review_id  review_stars  \\\n",
       "0  5UmKMjUEUNdYWqANhGckJw  2012-08-01  Ya85v4eqdd6k9Od8HbQjyA             4   \n",
       "1  5UmKMjUEUNdYWqANhGckJw  2014-02-13  KPvLNJ21_4wbYNctrOwWdQ             5   \n",
       "2  5UmKMjUEUNdYWqANhGckJw  2015-10-31  fFSoGV46Yxuwbr3fHNuZig             5   \n",
       "3  5UmKMjUEUNdYWqANhGckJw  2015-12-26  pVMIt0a_QsKtuDfWVfSk2A             3   \n",
       "4  5UmKMjUEUNdYWqANhGckJw  2016-04-08  AEyiQ_Y44isJmNbMTyoMKQ             2   \n",
       "\n",
       "                                                text    type  \\\n",
       "0  Mr Hoagie is an institution. Walking in, it do...  review   \n",
       "1  Excellent food. Superb customer service. I mis...  review   \n",
       "2  Yes this place is a little out dated and not o...  review   \n",
       "3  PROS: Italian hoagie was delicious.  Friendly ...  review   \n",
       "4  First the only reason this place could possibl...  review   \n",
       "\n",
       "                  user_id                                 votes  \n",
       "0  PUFPaY9KxDAcGqfsorJp3Q  {'funny': 0, 'useful': 0, 'cool': 0}  \n",
       "1  Iu6AxdBYGR4A0wspR9BYHA  {'funny': 0, 'useful': 0, 'cool': 0}  \n",
       "2  auESFwWvW42h6alXgFxAXQ  {'funny': 1, 'useful': 1, 'cool': 0}  \n",
       "3  qiczib2fO_1VBG8IoCGvVg  {'funny': 0, 'useful': 0, 'cool': 0}  \n",
       "4  qEE5EvV-f-s7yHC0Z4ydJQ  {'funny': 0, 'useful': 1, 'cool': 0}  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df = pd.DataFrame.from_dict(reviews)\n",
    "reviews_df.columns = ['business_id','date','review_id','review_stars','text','type','user_id','votes']\n",
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5UmKMjUEUNdYWqANhGckJw</td>\n",
       "      <td>Mr Hoagie is an institution. Walking in, it do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5UmKMjUEUNdYWqANhGckJw</td>\n",
       "      <td>Excellent food. Superb customer service. I mis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5UmKMjUEUNdYWqANhGckJw</td>\n",
       "      <td>Yes this place is a little out dated and not o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5UmKMjUEUNdYWqANhGckJw</td>\n",
       "      <td>PROS: Italian hoagie was delicious.  Friendly ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5UmKMjUEUNdYWqANhGckJw</td>\n",
       "      <td>First the only reason this place could possibl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id                                               text\n",
       "0  5UmKMjUEUNdYWqANhGckJw  Mr Hoagie is an institution. Walking in, it do...\n",
       "1  5UmKMjUEUNdYWqANhGckJw  Excellent food. Superb customer service. I mis...\n",
       "2  5UmKMjUEUNdYWqANhGckJw  Yes this place is a little out dated and not o...\n",
       "3  5UmKMjUEUNdYWqANhGckJw  PROS: Italian hoagie was delicious.  Friendly ...\n",
       "4  5UmKMjUEUNdYWqANhGckJw  First the only reason this place could possibl..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df = reviews_df[['business_id','text']]\n",
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "businessCI_df = business_df[(business_df.cuisine == 'Chinese') | (business_df.cuisine == 'Italian')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>cuisine</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SQ0j7bgSTazkVQlF5AnqyQ</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>Don Don is a restaurant I find myself missing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SQ0j7bgSTazkVQlF5AnqyQ</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>Take it from me; avoid this place at all cost....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SQ0j7bgSTazkVQlF5AnqyQ</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>Don Don is atleast as good as (although I pers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SQ0j7bgSTazkVQlF5AnqyQ</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>Far away from real Chinese food. Doesn't even ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SQ0j7bgSTazkVQlF5AnqyQ</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>I used to order takeout here once every month ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SQ0j7bgSTazkVQlF5AnqyQ</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>Delicious Singapore noodles and seafood deligh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SQ0j7bgSTazkVQlF5AnqyQ</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>I came here with two friends prior to visiting...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SQ0j7bgSTazkVQlF5AnqyQ</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>I use to order here fairly often.  The past 2 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SQ0j7bgSTazkVQlF5AnqyQ</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>We visited Don Don Chinese restaurant in Carne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>P1fJb2WQ1mXoiudj8UE44w</td>\n",
       "      <td>Italian</td>\n",
       "      <td>I brought my husband and my parents all to Pap...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id  cuisine  \\\n",
       "0  SQ0j7bgSTazkVQlF5AnqyQ  Chinese   \n",
       "1  SQ0j7bgSTazkVQlF5AnqyQ  Chinese   \n",
       "2  SQ0j7bgSTazkVQlF5AnqyQ  Chinese   \n",
       "3  SQ0j7bgSTazkVQlF5AnqyQ  Chinese   \n",
       "4  SQ0j7bgSTazkVQlF5AnqyQ  Chinese   \n",
       "5  SQ0j7bgSTazkVQlF5AnqyQ  Chinese   \n",
       "6  SQ0j7bgSTazkVQlF5AnqyQ  Chinese   \n",
       "7  SQ0j7bgSTazkVQlF5AnqyQ  Chinese   \n",
       "8  SQ0j7bgSTazkVQlF5AnqyQ  Chinese   \n",
       "9  P1fJb2WQ1mXoiudj8UE44w  Italian   \n",
       "\n",
       "                                                text  \n",
       "0  Don Don is a restaurant I find myself missing ...  \n",
       "1  Take it from me; avoid this place at all cost....  \n",
       "2  Don Don is atleast as good as (although I pers...  \n",
       "3  Far away from real Chinese food. Doesn't even ...  \n",
       "4  I used to order takeout here once every month ...  \n",
       "5  Delicious Singapore noodles and seafood deligh...  \n",
       "6  I came here with two friends prior to visiting...  \n",
       "7  I use to order here fairly often.  The past 2 ...  \n",
       "8  We visited Don Don Chinese restaurant in Carne...  \n",
       "9  I brought my husband and my parents all to Pap...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df =  pd.merge(businessCI_df,reviews_df,on='business_id')\n",
    "final_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For text analysis we use a code for the cuisine type, and make all of the text lowercase for stemming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>cuisine</th>\n",
       "      <th>text</th>\n",
       "      <th>cuisine_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SQ0j7bgSTazkVQlF5AnqyQ</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>don don is a restaurant i find myself missing ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SQ0j7bgSTazkVQlF5AnqyQ</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>take it from me; avoid this place at all cost....</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SQ0j7bgSTazkVQlF5AnqyQ</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>don don is atleast as good as (although i pers...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SQ0j7bgSTazkVQlF5AnqyQ</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>far away from real chinese food. doesn't even ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SQ0j7bgSTazkVQlF5AnqyQ</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>i used to order takeout here once every month ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SQ0j7bgSTazkVQlF5AnqyQ</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>delicious singapore noodles and seafood deligh...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SQ0j7bgSTazkVQlF5AnqyQ</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>i came here with two friends prior to visiting...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SQ0j7bgSTazkVQlF5AnqyQ</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>i use to order here fairly often.  the past 2 ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SQ0j7bgSTazkVQlF5AnqyQ</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>we visited don don chinese restaurant in carne...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>P1fJb2WQ1mXoiudj8UE44w</td>\n",
       "      <td>Italian</td>\n",
       "      <td>i brought my husband and my parents all to pap...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id  cuisine  \\\n",
       "0  SQ0j7bgSTazkVQlF5AnqyQ  Chinese   \n",
       "1  SQ0j7bgSTazkVQlF5AnqyQ  Chinese   \n",
       "2  SQ0j7bgSTazkVQlF5AnqyQ  Chinese   \n",
       "3  SQ0j7bgSTazkVQlF5AnqyQ  Chinese   \n",
       "4  SQ0j7bgSTazkVQlF5AnqyQ  Chinese   \n",
       "5  SQ0j7bgSTazkVQlF5AnqyQ  Chinese   \n",
       "6  SQ0j7bgSTazkVQlF5AnqyQ  Chinese   \n",
       "7  SQ0j7bgSTazkVQlF5AnqyQ  Chinese   \n",
       "8  SQ0j7bgSTazkVQlF5AnqyQ  Chinese   \n",
       "9  P1fJb2WQ1mXoiudj8UE44w  Italian   \n",
       "\n",
       "                                                text  cuisine_code  \n",
       "0  don don is a restaurant i find myself missing ...            -1  \n",
       "1  take it from me; avoid this place at all cost....            -1  \n",
       "2  don don is atleast as good as (although i pers...            -1  \n",
       "3  far away from real chinese food. doesn't even ...            -1  \n",
       "4  i used to order takeout here once every month ...            -1  \n",
       "5  delicious singapore noodles and seafood deligh...            -1  \n",
       "6  i came here with two friends prior to visiting...            -1  \n",
       "7  i use to order here fairly often.  the past 2 ...            -1  \n",
       "8  we visited don don chinese restaurant in carne...            -1  \n",
       "9  i brought my husband and my parents all to pap...             1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df[\"cuisine_code\"] = np.where(final_df[\"cuisine\"].str.contains(\"Italian\"), 1,-1)\n",
    "final_df['text'] = final_df['text'].str.lower()\n",
    "final_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of Chinese/Italian reviews: 215908\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-1,\n",
       " \"don don is a restaurant i find myself missing now and again, it's probably my favorite restaurant in carnegie. simple setup, just a small restaurant with a few tables and a tv. oddly enough i think my favorite thing to eat there is the wonton soup, never had better. the food is average but i always enjoyed eating there, great service and a cheap place to get chinese food.\")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcome_reviews = list(zip(final_df.cuisine_code,final_df.text))\n",
    "print(\"Total number of Chinese/Italian reviews: \" + str(len(outcome_reviews)))\n",
    "outcome_reviews[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\s+', gaps=True)\n",
    "\n",
    "# create English stop words list\n",
    "en_stop = set(get_stop_words('en'))\n",
    "# print(en_stop)\n",
    "# Create p_stemmer of class PorterStemmer\n",
    "p_stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc_set done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = []\n",
    "punctuation_string = '\\\"?!@#$%^&*()\\';:+,/.-|~=\\\\'\n",
    "table = str.maketrans(dict.fromkeys(punctuation_string))\n",
    "# loop through document list\n",
    "for index, row in final_df.iterrows():\n",
    "    # clean and tokenize document string\n",
    "    raw = row.text\n",
    "    raw = raw.translate(table)\n",
    "    tokens = tokenizer.tokenize(raw)\n",
    "    \n",
    "    # remove stop words from tokens\n",
    "    stopped_tokens = [j for j in tokens if not j in en_stop]\n",
    "    # print(tokens)\n",
    "    # stem tokens\n",
    "    stemmed_tokens = [p_stemmer.stem(k) for k in stopped_tokens]\n",
    "    \n",
    "    # add tokens to list\n",
    "    texts.append((final_df.cuisine_code[index], stemmed_tokens))\n",
    "\n",
    "print(\"doc_set done!\")\n",
    "os.system('say \"doc set done\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1,\n",
       " ['take',\n",
       "  'avoid',\n",
       "  'place',\n",
       "  'cost',\n",
       "  'time',\n",
       "  'go',\n",
       "  'starv',\n",
       "  'dont',\n",
       "  'energi',\n",
       "  'cook',\n",
       "  'get',\n",
       "  'edibl',\n",
       "  'food',\n",
       "  'kick'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[x[1] for x in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts_dictionary = corpora.Dictionary([x[1] for x in texts])\n",
    "print(\"there are: \" + str(len(texts)) + \" review documents in the dictionary\")\n",
    "print(\"dictionary done!\")\n",
    "os.system('say \"Finished dictionary\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_corpus(texts_tuple,dictionary):\n",
    "    text_list = [x[1] for x in texts_tuple]\n",
    "    return  [dictionary.doc2bow(text) for text in text_list]\n",
    "\n",
    "#corpus_p = make_corpus(texts_learn_p)\n",
    "#corpus_2p = make_corpus(texts_learn_2p)\n",
    "#corpus_all = make_corpus(texts_learn_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_dict = dict()\n",
    "def make_model_and_corpus(texts_tuple,num_top, num_pass, model_name,dictionary):\n",
    "    text_list = [x[1] for x in texts_tuple]\n",
    "    temp_corpus = make_corpus(texts_tuple,dictionary)\n",
    "    print(model_name)\n",
    "    temp_model = models.LdaMulticore(corpus=temp_corpus,num_topics=num_top,id2word=dictionary, passes=num_pass)\n",
    "    temp_model_corpus = temp_model[temp_corpus]\n",
    "    temp_outcomes = [x[0] for x in texts_tuple]\n",
    "    model_dict[model_name] = {\"model\": temp_model,\"model_corpus\": temp_model_corpus, \"outcomes\":temp_outcomes}\n",
    "    print(model_dict)\n",
    "    #model_dict[model_name] = {\"model\": models.ldamodel.LdaModel(corpus_name, num_topics=num_top, id2word = dictionary, passes=pass_num)}\n",
    "    \n",
    "    #modelname.save(\"/Users/rungsunan/spyder/yelpproject/\" + str(modelname))\n",
    "    #print(modelname + \" for \" + corpus + \" complete!\")\n",
    "       \n",
    "#make_model_and_corpus(corpus_p,2,5,\"lda_model_corpus_p\")\n",
    "#make_model_and_corpus(corpus_2p,2,5,\"lda_model_corpus_2p\")\n",
    "#make_model_and_corpus(corpus_all,2,5,\"lda_model_corpus_all\")\n",
    "def save_model_and_corpus(modelname):\n",
    "    model_dict[modelname]['model'].save('/Users/rungsunan/code/ADMfinal'+ modelname + '.model')\n",
    "    corpora.SvmLightCorpus.serialize('/Users/rungsunan/code/ADMfinal'+ modelname + '_corpus.svmlight', model_dict[modelname]['model_corpus'],labels=model_dict[modelname]['outcomes'])\n",
    "\n",
    "\n",
    "def load_ldamodel(modelname):\n",
    "    print(modelname)\n",
    "    X_temp, y_temp = load_svmlight_file(\"/Users/rungsunan/code/ADMfinal\" + modelname)\n",
    "    return (X_temp,y_temp)\n",
    "\n",
    "\n",
    "def train_svm(X, y):\n",
    "    \"\"\"\n",
    "    Create and train the Support Vector Machine.\n",
    "    \"\"\"\n",
    "    clf = svm.SVC(kernel='linear')\n",
    "    clf.fit(X, y)\n",
    "    return clf\n",
    "\n",
    "def histo_corpus(modelname):\n",
    "    histo = []\n",
    "    corpus = model_dict[modelname]['model_corpus']\n",
    "    for doc in corpus:\n",
    "        for i in range(len(doc)):\n",
    "            if doc[i][1] > .1:\n",
    "                histo.append(doc[i][0])\n",
    "    return histo\n",
    "\n",
    "\n",
    "def best_topics (texts_tuple, dictionary):\n",
    "    grid = defaultdict(list)\n",
    "    param_list = []\n",
    "    perplex_list = []\n",
    "    perword_list = []\n",
    "    text_list = [x[1] for x in texts_tuple]\n",
    "    temp_corpus = [dictionary.doc2bow(text) for text in text_list]\n",
    "    number_of_words = sum(cnt for document in temp_corpus for _, cnt in document)\n",
    "    parameter_list = [2,3,4,5,10,30,75,120]\n",
    "    for parameter_value in parameter_list:      \n",
    "        print (\"starting pass for parameter_value = %.3f\" % parameter_value)\n",
    "        model = models.LdaMulticore(corpus=temp_corpus, workers=None, id2word=dictionary, num_topics=parameter_value, passes=4, iterations=20)\n",
    "        perplex = model.bound(temp_corpus) # this is model perplexity not the per word perplexity\n",
    "        print (\"Total Perplexity: %s\" % perplex)\n",
    "        param_list.append(parameter_value)\n",
    "        perplex_list.append(perplex)\n",
    "        grid[parameter_value].append(perplex)\n",
    "\n",
    "    \n",
    "        per_word_perplex = np.exp2(-perplex / number_of_words)\n",
    "        perword_list.append(per_word_perplex)\n",
    "        print (\"Per-word Perplexity: %s\" % per_word_perplex)\n",
    "        grid[parameter_value].append(per_word_perplex)\n",
    "        #model.save(data_path + 'ldaMulticore_i10_T' + str(parameter_value) + '_training_corpus.lda')\n",
    "\n",
    "    for numtopics in parameter_list:\n",
    "        print (numtopics, '\\t',  grid[numtopics])\n",
    "    df = pandas.DataFrame(grid)\n",
    "    ax = plt.figure(figsize=(7, 4), dpi=300).add_subplot(111)\n",
    "    df.iloc[1].transpose().plot(ax=ax,  color=\"#254F09\")\n",
    "    plt.xlim(parameter_list[0], parameter_list[-1])\n",
    "    plt.ylabel('Perplexity')\n",
    "    plt.xlabel('topics')\n",
    "    plt.title('')\n",
    "    plt.show()\n",
    "    #df.to_pickle(data_path + 'gensim_multicore_i10_topic_perplexity.df')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_sample_set(text_tuple,set_size):\n",
    "    temp_texts = resample(text_tuple, replace = False, n_samples = set_size)\n",
    "    return(temp_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts_outcome_p100 = create_sample_set(texts,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts_outcome_p100[9]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts_outcome_p100k = create_sample_set(texts,100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts_outcome_p1k = create_sample_set(texts,1000)\n",
    "texts_outcome_p3k = create_sample_set(texts,3000)\n",
    "texts_outcome_p7k = create_sample_set(texts,7000)\n",
    "texts_outcome_p10k = create_sample_set(texts,10000)\n",
    "texts_outcome_p50k = create_sample_set(texts,50000)\n",
    "texts_outcome_p100k = create_sample_set(texts,100000)\n",
    "texts_outcome_all = create_sample_set(texts,len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_topics(texts_outcome_p100, texts_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_topics(texts_outcome_p1k, texts_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_topics(texts_outcome_p100k, texts_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_topics(texts_outcome_p1k, texts_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_topics(texts_outcome_p3k,texts_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_topics(texts_outcome_p10k,texts_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_topics(texts_outcome_p50k,texts_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus_p100k = make_corpus(texts_outcome_p100k,texts_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus_all = make_corpus(texts_outcome_all,texts_dictionary)\n",
    "corpus_p10k = make_corpus(texts_outcome_p10k,texts_dictionary)\n",
    "corpus_p50k = make_corpus(texts_outcome_p50k,texts_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "make_model_and_corpus(texts_outcome_p100,4  ,10,\"lda_model_p100_4topics\",texts_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "make_model_and_corpus(texts_outcome_p1k,5  ,10,\"lda_model_p1k_5topics\",texts_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "make_model_and_corpus(texts_outcome_p50k,5  ,10,\"lda_model_p50k_5topics\",texts_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_dict['lda_model_p50k_5topics']['outcomes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_model_and_corpus('lda_model_p100_4topics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_model_and_corpus('lda_model_p1k_5topics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_model_and_corpus('lda_model_p50k_5topics')\n",
    "#save_model_and_corpus('lda_model_p10k_2topics')\n",
    "#save_model_and_corpus('lda_model_p10k_3topics')\n",
    "#save_model_and_corpus('lda_model_p10k_10topics')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(X_p100_4topics, y_p100_4topics) = load_ldamodel(\"lda_model_p100_4topics_corpus.svmlight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(X_p1k_5topics, y_p1k_5topics) = load_ldamodel(\"lda_model_p1k_5topics_corpus.svmlight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#(X_all_2topics, y_all_2topics) = load_ldamodel(\"lda_model_all_2topics_corpus.svmlight\")\n",
    "#(X_p100k_5topics, y_p100k_5topics) = load_ldamodel(\"lda_model_p100k_5topics_corpus.svmlight\")\n",
    "#(X_p10k_3topics, y_p10k_3topics) = load_ldamodel(\"lda_model_p10k_3topics_corpus.svmlight\")\n",
    "#(X_p10k_10topics, y_p10k_10topics) = load_ldamodel(\"lda_model_p10k_10topics_corpus.svmlight\")\n",
    "#(X_p50k_5topics, y_p50k_5topics) = load_ldamodel(\"lda_model_p50k_5topics_corpus.svmlight\")\n",
    "(X_p50k_5topics, y_p50k_5topics) = load_ldamodel(\"lda_model_p50k_5topics_corpus.svmlight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_p50k_5topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X_train_all_2topics, X_test_all_2topics, y_train_all_2topics, y_test_all_2topics = train_test_split(\n",
    "#  X_all_2topics, y_all_2topics, test_size=0.2, random_state=0)\n",
    "#X_train_p100k_5topics, X_test_p100k_5topics, y_train_p100k_5topics, y_test_p100k_5topics = train_test_split(\n",
    "#  X_p100k_5topics, y_p100k_5topics, test_size=0.2, random_state=0)\n",
    "#X_train_p10k_3topics, X_test_p10k_3topics, y_train_p10k_3topics, y_test_p10k_3topics = train_test_split(\n",
    "#  X_p10k_3topics, y_p10k_3topics, test_size=0.2, random_state=0)\n",
    "#X_train_p10k_10topics, X_test_p10k_10topics, y_train_p10k_10topics, y_test_p10k_10topics = train_test_split(\n",
    "#  X_p10k_10topics, y_p10k_10topics, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_p50k_5topics, X_test_p50k_5topics, y_train_p50k_5topics, y_test_p50k_5topics = train_test_split(\n",
    "    X_p50k_5topics, y_p50k_5topics, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test_p50k_5topics = y_test_p50k_5topics.astype(list).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_p50k_5topics = np.asarray(X_train_p50k_5topics.todense())\n",
    "X_test_p50k_5topics = np.asarray(X_test_p50k_5topics.todense())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.shape(y_train_p50k_5topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(y_test_p50k_5topics[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_p50k_5topics[10:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(y_test_p50k_5topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k_range = [1,3,5,7,11,15,21,31]\n",
    "param_grid = dict(n_neighbors=k_range)\n",
    "knn=KNeighborsClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn.fit(X_p50k_5topics,y_p50k_5topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn.predict(X_p50k_5topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid=GridSearchCV(knn,param_grid,cv=3,scoring='accuracy',n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid.fit(X_p100_4topics,y_p100_4topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid.fit(X_p1k_5topics,y_p1k_5topics)\n",
    "grid.grid_scores_\n",
    "grid.cv_results_['mean_test_score']\n",
    "grid.cv_results_\n",
    "s = [result.mean_validation_score for result in grid.grid_scores_]\n",
    "print(grid.cv_results_['mean_test_score'][0])\n",
    "plt.plot(k_range,grid.cv_results_['mean_test_score'])\n",
    "plt.xlabel('Value of K for KNN')\n",
    "plt.ylabel('Cross-Validated Accuracy')\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "print(grid.best_estimator_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid.fit(X_p50k_5topics,y_p50k_5topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#grid.fit(X_p10k_2topics,y_p10k_2topics)\n",
    "grid.grid_scores_\n",
    "grid.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = [result.mean_validation_score for result in grid.grid_scores_]\n",
    "print(grid.cv_results_['mean_test_score'][0])\n",
    "plt.plot(k_range,grid.cv_results_['mean_test_score'])\n",
    "plt.xlabel('Value of K for KNN')\n",
    "plt.ylabel('Cross-Validated Accuracy')\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "print(grid.best_estimator_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tuned_parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10,100,1000]}\n",
    "scores = ['precision','recall']\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(svm.SVC(), tuned_parameters, cv=10,\n",
    "                       scoring='%s_macro' % score,n_jobs=-1)\n",
    "    clf.fit(X_train_p50k_5topics, y_train_p50k_5topics)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true_p50k_5topics, y_pred_p50k_5topics = y_test_p50k_5topics, clf.predict(X_test_p50k_5topics)\n",
    "    print(classification_report(y_true_p50k_5topics, y_pred_p50k_5topics))\n",
    "    print(confusion_matrix(y_true_p50k_5topics, y_pred_p50k_5topics))\n",
    "    print()\n",
    "    os.system('say \"doc set done\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tuned_parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10,100,1000]}\n",
    "scores = ['precision','recall']\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(svm.SVC(), tuned_parameters, cv=10,\n",
    "                       scoring='%s_macro' % score,n_jobs=-1)\n",
    "    clf.fit(X_train_p50k_5topics, y_train_p50k_5topics)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true_p50k_5topics, y_pred_p50k_5topics = y_test_p50k_5topics, clf.predict(X_test_p50k_5topics)\n",
    "    print(classification_report(y_true_p50k_5topics, y_pred_p50k_5topics))\n",
    "    print(confusion_matrix(y_true_p50k_5topics, y_pred_p50k_5topics))\n",
    "    print()\n",
    "    os.system('say \"doc set done\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyLDAvis  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "histo_2p = histo_corpus(\"lda_model_p2\")\n",
    "plt.hist(histo_2p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
